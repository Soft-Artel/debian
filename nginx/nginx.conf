user  www-data;

# = cpu cores
worker_processes  4;

pid /var/run/nginx.pid;

# Number of file descriptors used for Nginx. This is set in the OS with 'ulimit -n 200000' or using /etc/security/limits.conf
worker_rlimit_nofile 200000;

# only log critical errors
error_log /var/log/nginx/error.log info;

events {
        # Determines how many clients will be served by each worker process.
        # (Max clients = worker_connections * worker_processes)
        # "Max clients" is also limited by the number of socket connections available on the system (~64k)
        worker_connections 4000;

        # essential for linux, optmized to serve many clients with each thread
        use epoll;

        # Accept as many connections as possible, after nginx gets notification about a new connection.
        # May flood worker_connections, if that option is set too low.
        multi_accept on;

        # debug_connection 192.168.0.101;
        # debug_connection 192.168.0.30;
        #debug_connection 192.168.0.31;
        #debug_connection 127.0.0.1;
}

http {

        # Caches information about open FDs, freqently accessed files.
        # *no need, because bn api not work with files
        open_file_cache max=200000 inactive=20s;
        open_file_cache_valid 30s;
        open_file_cache_min_uses 2;
        open_file_cache_errors on;

        include /etc/nginx/mime.types;
        default_type application/octet-stream;
        
        log_format main
            '$remote_addr - $remote_user [$time_local] '
            '"$request" $status $bytes_sent $upstream_response_time '
            '"$http_referer" "$http_user_agent" '
            '"$gzip_ratio" "$host"';

        # Buffer log writes to speed up IO, or disable them altogether
        access_log /var/log/nginx/access.log main buffer=16k;
        # access_log off;

        # Sendfile copies data between one FD and other from within the kernel.
        # More efficient than read() + write(), since the requires transferring data to and from the user space.
        sendfile on;

        # Tcp_nopush causes nginx to attempt to send its HTTP response head in one packet, instead of using partial frames. This is useful for prepending headers before calling sendfile, or for throughput optimization.
        tcp_nopush on;

        # don't buffer data-sends (disable Nagle algorithm). Good for sending frequent small bursts of data in real time.
        tcp_nodelay on;

        # Timeout for keep-alive connections. Server will close connections after this time.
        # keepalive_timeout 30;
        # *disable keepalive - native bn api clients not support it
        keepalive_timeout 0;

        # Number of requests a client can make over the keep-alive connection. This is set high for testing.
        # keepalive_requests 100000;

        # allow the server to close the connection after a client stops responding. Frees up socket-associated memory.
        reset_timedout_connection on;

        # send the client a "request timed out" if the body is not loaded by this time. Default 60.
        client_body_timeout 10;

        # If the client stops reading data, free up the stale client connection after this much time. Default 60.
        send_timeout 2;

        # Compression. Reduces the amount of data that needs to be transferred over the network
        gzip on;
        gzip_min_length 10240;
        gzip_proxied expired no-cache no-store private auth;
        gzip_types text/plain text/css text/xml text/javascript application/x-javascript application/xml;
        gzip_disable "MSIE [1-6]\.";

        fastcgi_buffers 16 16k;
        fastcgi_buffer_size 32k;

        # Redis factory
        upstream redis_factory {
                server 127.0.0.1:6379;
        }

        # fcgi factory
        upstream php_factory {
                server 127.0.0.1:9000;
                # server unix:/var/run/php5-fpm.sock;
                # wait 1.1.14 for this option
                keepalive 32;
        }

        # for munin
        server {
                listen 127.0.0.1:80;
                server_name 127.0.0.1;

                # пока тут, на этап тестирования, потом перенесем только в ответы на меж-серверные запросы
                chunked_transfer_encoding off;

                # show nginx status for munin
                location = /nginx_status/ {
                        stub_status on;
                        access_log off;
                        allow 127.0.0.1;
                        deny all;
                }

                # show php pool status for munin (must be same url to same fcgi server)
                location ~ ^/php_(status|ping)/$ {
                        access_log off;
                        include fastcgi_params;
                        fastcgi_pass 127.0.0.1:9000;
                        fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;
                        allow 127.0.0.1;
                        deny all;
                }

                # show php eaccelerator (opcode cacher) status for munin (must be same url to same fcgi server)
                location = /php_eaccelerator/ {
                        access_log   off;
                        include fastcgi_params;
                        fastcgi_pass 127.0.0.1:9000;
                        fastcgi_param SCRIPT_FILENAME /usr/share/munin/plugins/munin-eaccelerator-plugin/stats.php;
                        allow 127.0.0.1;
                        deny all;
                }
        }

        server {
                listen 80;
                recursive_error_pages on;

                location /munin {
                        access_log off;
                        index index.html;
                        root /var/wwws;
                }

                include

        }        

        # here is servers and locations
}
