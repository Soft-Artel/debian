
user  nginx;

# = cpu cores
worker_processes  4;

pid /var/run/nginx.pid;

# Number of file descriptors used for Nginx. This is set in the OS with 'ulimit -n 200000' or using /etc/security/limits.conf
worker_rlimit_nofile 200000;

# only log critical errors
error_log /var/log/nginx/error.log warn;

events {
	# Determines how many clients will be served by each worker process.
	# (Max clients = worker_connections * worker_processes)
	# "Max clients" is also limited by the number of socket connections available on the system (~64k)
	worker_connections 4000;

	# essential for linux, optmized to serve many clients with each thread
	use epoll;

	# Accept as many connections as possible, after nginx gets notification about a new connection.
	# May flood worker_connections, if that option is set too low.
	multi_accept on;

}

http {

	# Caches information about open FDs, freqently accessed files.
	# *no need, because bn api not work with files
	open_file_cache max=200000 inactive=20s;
	open_file_cache_valid 30s;
	open_file_cache_min_uses 2;
	open_file_cache_errors on;

	include /etc/nginx/mime.types;
	# default_type application/octet-stream;

	types {
		application/json json;
	}

	etag off;
	if_modified_since off;

	server_tokens off;

	log_format auth_main		'$time_local [$msec] $remote_addr $request DID=$http_device_id CTS=$http_device_ts RID=$http_run_id HCT=$http_content_type HCL=$http_content_lenght POST=$request_body STATUS=$status SENT=$body_bytes_sent TIME=$request_time UTIME=$upstream_response_time';
	log_format api_main			'$time_local [$msec] $remote_addr $request UID=$http_user_id DID=$http_device_id CTS=$http_device_ts SIG=$http_signature RID=$http_run_id HCT=$http_content_type HCL=$http_content_lenght POST=$request_body STATUS=$status SENT=$body_bytes_sent TIME=$request_time UTIME=$upstream_response_time';
	log_format file_main		'$time_local [$msec] $remote_addr $request UID=$http_user_id DID=$http_device_id CTS=$http_device_ts SIG=$http_signature RID=$http_run_id HCT=$http_content_type HCL=$http_content_lenght POST=$request_body STATUS=$status SENT=$body_bytes_sent TIME=$request_time UTIME=$upstream_response_time';
	log_format web				'$time_local [$msec] $remote_addr "$request" $status $bytes_sent $upstream_response_time "$http_referer" "$http_user_agent" "$gzip_ratio" "$host"';


	# Buffer log writes to speed up IO, or disable them altogether
	# access_log /var/log/nginx/access.log main buffer=16k;
	# access_log off;
	access_log /var/log/nginx/access.log web;

	# Sendfile copies data between one FD and other from within the kernel.
	# More efficient than read() + write(), since the requires transferring data to and from the user space.
	sendfile on;

	# Tcp_nopush causes nginx to attempt to send its HTTP response head in one packet, instead of using partial frames. This is useful for prepending headers before calling sendfile, or for throughput optimization.
	tcp_nopush on;

	# don't buffer data-sends (disable Nagle algorithm). Good for sending frequent small bursts of data in real time.
	tcp_nodelay on;

	# Timeout for keep-alive connections. Server will close connections after this time.
	# keepalive_timeout 30;
	# *disable keepalive - native bn api clients not support it
	keepalive_timeout 0;

	# Number of requests a client can make over the keep-alive connection. This is set high for testing.
	# keepalive_requests 100000;

	# allow the server to close the connection after a client stops responding. Frees up socket-associated memory.
	reset_timedout_connection on;

	# send the client a "request timed out" if the body is not loaded by this time. Default 60.
	client_body_timeout 10;
	
	client_max_body_size 1G;
	client_body_buffer_size 1024k;

	# If the client stops reading data, free up the stale client connection after this much time. Default 60.
	send_timeout 2;

	# Compression. Reduces the amount of data that needs to be transferred over the network
	gzip on;
	gzip_min_length 100;
	gzip_proxied any;
	gzip_comp_level  6;
	gzip_types text/plain text/css text/xml text/javascript application/json application/x-javascript application/xml;

	fastcgi_buffers 16 16k;
	fastcgi_buffer_size 32k;

		
	init_by_lua_file /var/wwws/api-v2.bossnote.ru/htdocs/lua/api-init.lua;

	# Redis factory
	upstream redis_factory {
		server 127.0.0.1:6379;
	}

	# fcgi factory
	upstream php_factory {
		server 127.0.0.1:9000;
		# server unix:/var/run/php5-fpm.sock;
		# wait 1.1.14 for this option
		keepalive 32;
	}


	server {

		listen 80;

		# for munin
		# когда будет на продакшене, то это надо вытащить в отдельный server контейнер listen 127.0.0.1:80

		# пока тут, на этап тестирования, потом перенесем только в ответы на меж-серверные запросы
		chunked_transfer_encoding off;

		# show nginx status for munin
		location = /nginx_status/ {
			stub_status on;
			access_log off;
			allow 127.0.0.1;
			deny all;
		}
		# show php pool status for munin (must be same url to same fcgi server)
		location ~ ^/php_(status|ping)/$ {
			access_log off;
			include fastcgi_params;
			fastcgi_pass 127.0.0.1:9000;
			fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;
			allow 127.0.0.1;
			deny all;
		}
		# show php eaccelerator (opcode cacher) status for munin (must be same url to same fcgi server)
		location = /php_eaccelerator/ {
			access_log off;
			include fastcgi_params;
			fastcgi_pass 127.0.0.1:9000;
			fastcgi_param SCRIPT_FILENAME /usr/share/munin/plugins/munin-eaccelerator-plugin/stats.php;
			allow 127.0.0.1;
			deny all;
		}

		# тут пошли разные штучки для администрирования
		location /munin {
			access_log off;
			index index.html;
			root /var/wwws;
		}
		#
		location /phpredisadmin {
			access_log off;
			root /var/wwws;
			index index.php;
			try_files $uri @phpredisadmin;
			open_file_cache_errors off;
		}
		location ~* ^/phpredisadmin.+\.(php|phtml)$ {
			access_log off;
			root /var/wwws;
			fastcgi_index index.php;
			include fastcgi_params;
			fastcgi_pass php_factory;
			fastcgi_param DOCUMENT_ROOT /var/wwws/phpredisadmin;
			fastcgi_param SCRIPT_FILENAME /var/wwws$fastcgi_script_name;
		}
		location @phpredisadmin {
			access_log off;
			fastcgi_index index.php;
			include fastcgi_params;
			fastcgi_pass php_factory;
			fastcgi_param DOCUMENT_ROOT /var/wwws/phpredisadmin;
			fastcgi_param SCRIPT_FILENAME /var/wwws/phpredisadmin/index.php;
		}
		#
		location /phpmyadmin {
			access_log off;
			root /var/wwws;
			index index.php;
		}
		location ~* ^/phpmyadmin.+\.(php|phtml)$ {
			access_log off;
			root /var/wwws;
			fastcgi_index index.php;
			include fastcgi_params;
			fastcgi_pass php_factory;
			fastcgi_param DOCUMENT_ROOT /var/wwws/phpmyadmin;
			fastcgi_param SCRIPT_FILENAME /var/wwws$fastcgi_script_name;
		}


		# api и т.п. пошло
		recursive_error_pages on;


		# api-v2
		include conf.d/*;

	}

}


